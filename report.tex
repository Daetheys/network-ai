\documentclass[11pt]{article}
%Gummi|065|=)
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{changepage}
\usepackage{graphicx}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\title{\textbf{Detecting lateral movements on huge active networks}}
\author{Nicolas YAX}
\date{}
\begin{document}

\maketitle


\section{What are lateral movements ?}

Nowadays networks are more protected from North-South attacks (coming from the outside of the network) rather than West-East attacks (coming from the inside the network). This affects on many aspects methods hackers use to get information from networks in order to make profit (black mail, selling stolen databases, ...). Actually it's very effective to enter a network and to spy it from the inside getting higher and higher privileges to access more and more files and in the end reach databases and important files.This vulnerability of actual netorks is particularly alarming the more remote work develops (IT companies are particularly vulnerable and the lockdown is a real playground for hackers especially because it's sudden and companies haven't had enough time to prepare for it). \\
The scheme of lateral movement attacks is the following : 
\begin{enumerate}
\item Find an entry point : you first need to access the network. To do so several methods can be used. The most common one is phishing but it's also possible to use different exploits when zero-day vulnerabilities are disclosed (usually people need a month to patch them). Once you have access to an account you can start moving inside the network.
\item Explore the network : from an account you have access to various systems on the network (computers, printers, microscopes, ...). You can now start mapping the network and see its topology, who is administrator, where are interesting data and known vulnerabilities of services. This is the spying part where you can read files the account has access to. The hacked account may also have administrator rights on several services which means you can access even more files.\\
\item Movement phase : When you have done everything you wanted to do with the hacked account services it's time to move on and to hack other accounts in order to get access to other services and files. To do so you can use several tricks (mimikatz,steal tokens, ...). It's usually far easier if your account is administrator of at least one service because you can use exploits (such as mimikatz to dump passwords from the memory of accounts logged on the service). That's why it's crucial to hack administrator accounts to higher your priviledges and hack the other accounts more easily. 

However network administrators usually don't get caught by phishing mails which means it's more realistic to find an easy entry point (like an intern or to focus on people vulnerable such as people who aren't aware of risks and are in touch with many other people about various projects like the secretary). Once you've access to a new account you can repeat phase 2.
\end{enumerate}
This method is particularly effective because you stay hidden in the network activity and it may become very hard to spot your activity hidden close to all other communications. When account A accesses data D how do you know whether it's the real person behind account A or a hacker trying to remotely spy the network ? 

However these attacks aren't perfect : you need to have access to accounts to get access to files and services. If the password is changed when you are in phase 2 you lose access to the account and it strongly slows your exploration. This means if all passwords are changed hackers lose control over the network. They still know the topology of the network and files they have already read but they need to find an other entry point (which might take a while). This way if passwords are regularly changed lateral movements attacks are highly slowed. 

Moreover to get access to crucial data an attacker needs to be really quick and to infect as many accounts as possible before passwords are changed and such a behaviour is easy to spot. Using such a technology is a real barriere to lateral movements attacks because either the hacker is spotted very fast or he won't be able to access many files (and there is a low probability for him to find something relevant to make money).
\paragraph{Assumption 1:}
Passwords are changed every \textit{password\_time}.
\paragraph{}
Obviously it's very unconvenient to have passwords changing too often and I will talk about an innovant way to do so in the end of this report. (we can achieve \textit{password\_time} = 5 min for high security servers very easily which completely kills lateral movement attacks in those networks).\\
\paragraph{}
Nonetheless changing passwords may be pointless if keyloggers are installed on services. A keylogger will send every password to the hacker who can then continue his work. Nevertheless a keylogger needs to send passwords from the target service to an other server controlled by the hacker and this is too strange to happen in a profesional network. It's very easy to see where packets are sent from your computer and if it's currently talking with an unknown computer using a russian VPN for example it's obvious that a hacker controls this server and this IP should be blocked by a firewall automatically. 

The only vulnerable servers are webservers because they constantly talk with unknown computers/servers/VPN. However those servers are targeted by attacks several times a day and thus are under very high security which means it should be almost impossible to send password through them without being spotted. Usually they are formatted to only output specific packets such as specific webpages and sending a password would be too obvious and spotted very quickly. Thus using a keylogger to counter this strategy would be almost impossible in a real and serious environment.

\section{How to spot lateral movements ?}
\subsection{Model}
\indent Lateral movements are caraterised by the spread of access to services through accounts hacking. First let's see the model we will use to spot those movements :\\
\indent Let $S=(V_s,E_s)$ be the service graph with $V_s$ the set of nodes representing services (they may be various different services but we won't make any differrence between a printer and a computer) and $E_s$ be the set of conections between services (such as a printer connected to a set of computers).\\
\indent Let $A=(V_a,E_{as})$ be the account graph with $V_a$ the set of nodes representing accounts and $E_{as}$ the set of access to services. Actually to make it very simple we won't make a difference between an administrator and a simple user of a service. $a\in V_a$ has access or hasn't access to $s\in V_s$.\\
\indent Those 2 graphs define the topology of the network. Let's now define the vulnerability graph which will be used to detect lateral movements. Let $V=(V_a,E_v)$ be the vulnerability graph where $V_a$ is the set of accounts and $E_v$ is the set of edges where when a hacker has access to $a\in V_a$ and $(a,a')\in E_v$ it may hack $a'\in V_a$. 

If two users have access to the same service and one of them's account is hacked then the second's account may be compromised (see mimikatz to dump passwords from memory or token stealing methods). It' also possible from a service to send a malware to an other connected service to get access to an account logged on. These two ways to infect the other accounts will be used to define the vulnerability graph. 

\begin{figure}[!h]
\centering
\includegraphics[scale=0.40]{graphs.jpg}
\caption{Example of graphs S A V}
\label{graphs}
\end{figure}

Thus $(a,a')\in E_v$ iff ($\exists s\in V_s. (a,s)\in E_{as}$ and $(a',s)\in E_{as}$) or\\ ($\exists s\in V_s. \exists s'\in V_s. (a,s)\in E_{as}$ and $(a',s')\in E_{as}$ and $(s,s')\in E_s$). Which formally express what we have just talked about (see \ref{graphs}).

\subsection{Node anomaly detection}

Passwords are changed every \textit{password\_time} which stops the propagation of attacks in the network. That means everything will happen in the interval \textit{password\_time} and then will be reset. We can now define sequences of events \cite{node}. 

To introduce fingerprints we'll need an other set : let $F_1 = \{ \{s\in V_s \| (a,s) \in E_{as}\} \| a\in V_a\}$. This set is the set of authorisation terroritories of users. It defines sets of services accounts have exactly access too. When a hacker has access to an account he will explore all these services and it might be easy to see because all services of a spectific user's territory would be explored very quickly.

Basically when service $s\in V_s$ is accessed by account $a\in V_a$ for the first time of the interval an event with fingerprint $\{e\in F_1 \| s \in e\}\subset F_1$ is created. This fingerprint says that $s\in V_s$ within various territories of many users has been accessed. If a territory is fully accessed it will be noticed and users who have access to this territory might be infected. With this first analysis it's hard to know who has been infected. In fact the hacker may be smart enough to not access too many services with a single account but to explore few of them on each account (in pratice many services are accessible to everyone - like a printer) so as to explore them all. This way we can see the portion of territories that has been accessed independently of the account used for it which is more relevant to understand the propagation of lateral movements inside the network.That's also why it's important to have a small integration time and reset often to clean data (usually users won't access all their services every hour).\\
\indent During this interval we will record various events defining a event stream on which we can apply the node anomaly algorithm. Events aren't truely independent because one may need to remotely access his computer so as to remotely access the printer. For example on a 2 services network with a single account, P($access\_computer\|access\_printer$) is 1 but P($access\_computer$) isn't 1. However we'll consider that globaly on huge networks with many services, accounts and a high activity (many events each second) it's independent. The number of services is bounded by N=$\|V_s\|$ so the lenght of the event stream is deterministic (by adding empty events at the end of the stream to get exactly N events).\\
\indent To get a better understanding about what is happening in the network we will run an other instance of the node anomaly algorithm with $F_2 = V_a \cup V_s$ where when $a\in V_a$ accesses $s\in V_s$ for the first time an event with fingerprint $\{a,s\} \subset F_2$ is created. This is particularly usefull to spot hackers who are stressed by the timer due to password reset and who would want to access too many services with a single account. It is relevant to find the entry point because it will have an abnormal number of accesses even if next infected account will access less services (because they may already have been visited). This way by combining both analysis we can get a pretty good understanding about what is happening in the network. We will still consider events are independent in huge networks.\\
\indent Given a treshold $\alpha$ for the confidence level (must be adapted to the network activity) the node anomaly algorithm will return $e\in F_{\{1,2\}}$ which is too or not enough active in events. We only want to know when it's too active which means when $M_t^{j} > \mu^*+\sqrt{\dfrac{n_tlog(2/\delta)}{2}}$ (see \cite{node} equation (5)). \\
\indent When such an anomaly is detected it's probably an ongoing attack. 

We could stop there but reserting passwords very often has drawbacks : we'll lack of statistical data. It's very probable that in a network activities of users are continuous : user 1 might be working on an update of a service and will access it a lot during few days and then move to an other system. The short time between resets might be an issue and creates many false positives. That's the first reason why a second layer is relevant.

\subsection{Temporal integration layer}

The second one is that diagnosis can be highly improved using the vulnerability graph. We will follow alerts raised on accounts linked to warned territories and accounts with a suspicious activity. The algorithm runs on subsequences of the whole sequence which means we can put a time marker on each alert. We will run the node anomaly algorithm on each substream starting from the first event until each other event of the whole stream. This way we can integrate temporally what is happening in the network and results of the algorithm will be labeled by the timestep of the last event of the sequence. This algorithm is better when it runs online so as to compute a single other step each time you get a new event (see annexe 1 for the pseudo code). Basically the output of those 2 node anomaly runs are 2 event streams $S_1$ and $S_2$ on the vulnerability graph.

To be more precise $S_1$ is a stream on $F_1$ but there is a link between $F_1$ and $V_a$ : for each territory we can assign a set of users that have exactly access to those services. $S_1$ is thus the stream of those associated accounts. $S_2$ should be a stream on $F_2=V_a\cup V_s$ but we are only interested in events on $V_a$ so we will project $F_2$ on $V_a$ to create $S_2$. We don't mind about anomaly on services because they refer to an overusage of a service which is not a consequence of lateral movements - a hacker will connect once to a service, completely explore it and never see it again. 

Let $S$ be the union of both $S_1$ and $S_2$ and $time$ be the sorted union of time markers of $S$. This stream will also have weights associated to events. Basically when $e$ is in $S$ it means every node in the fingerprint has a $M_i^{(j)} > \mu^*+\sqrt{\dfrac{n_tlog(2/\delta)}{2}}$ and the weight associated with each node j will be $w = M_i^{(j)} - (\mu^*+\sqrt{\dfrac{n_tlog(2/\delta)}{2}})$ ($>0$ because we only take events linked to an overactivity of a node). Weighted events streams are thus a sequence of events like this : $(t,weighted fingerprint)$ and a $weighted\_fingerprint$ is a set of $(node,weight)$.

Each event alerts about several nodes that may be corrupted. We now need to add a temporal coherence on those data to find a possible progressive lateral movement chain. We'll create a temporal vulnerability graph $Temp_V=(V_{temp_V},E_{temp_V})$ where 
\begin{itemize}
\item $V_{temp_V} = \{(a,t) \|a \in V_a, t\in time\}$
\item $E_{temp_V} = E_1 \cup E_2$ with

\begin{equation*}
E_1 = \{((a,t^{(3)}),(a',t),w) \|
\begin{cases}
\exists (t',f)\in S_1.t'<t,(a,w')\in f,(a,a')\in E_V,\mbox{ (1)}\\
(t,f')\in S_1,(a',w'')\in f'\mbox{ (2)}\\
\mbox{$t^{(3)}$ is right before t in $time$},\mbox{ (3)}\\
\begin{split}
w=max(w^{(3)}\|(a,f'')\in S_1.t'<t,(a,w^{(3)})\in f'',(a,a')\in E_V)+w''\\\mbox{ (4)}
\end{split}
\end{cases}\}
\end{equation*}
\begin{equation*}
\begin{split}
\mbox{$E_2 = \{((a,t),(a,t'),w) \|$}
\begin{cases}
\mbox{t' is right after t in $time$,\mbox{ (5)}}\\
w = \begin{cases}
\mbox{$w'$ if $(t,f)\in S_2,(a,w')\in f$}\\
\mbox{0 else}
\end{cases}\mbox{ (6)}
\end{cases}\}
\end{split}
\end{equation*}
\end{itemize}

This graph is oriented. Basically we have duplicated nodes so that they all have a time marker and they will be oriented to their future or the others' future. We assume that each lateral movement will take at least one timestep (if the algorithm is refreshed each new event it's verified because in practice it's impossible to access two files at the exact same instant).

$E_1$ refers to connections between nodes such as lateral movements while $E_2$ represents connections between each node and their future one timestep after. Weights in $E_1$ are defined using $S_1$. This means that if account $a$ has already been spotted as possibly compromised (1) and acccount $a'$ has just been spotted too (2) then a connection between $a$ and $a'$ will be created. The graph must not have cycles in it because we will run a longest path algorithm on it. That's why we can only connect nodes from different timesteps toward the future of the graph. Thus we connect ($a,t^{(3)}$) with ($a',t'$) which means $a$ one timestep before $a'$ has been spotted to $a'$ when it's spotted (3). The associated weight must reveal the reliability of this potential lateral movement. The more $a$ is possibly infected the more the weight should be high. That's why we put the maximum of all alerts found on $a$ since the creation of $Temp_V$ and we add the weight given for $a'$ by $S_1$ (4).

$E_2$ is the link between each node and it's future in the graph. It has links coming from a node $a$ at timestep $t$ and the next version at timestep $t'$ right after $t$ in the stream $S$ (5).Weights are defined using $S_2$ : if the account $a$ has a high activity it's suspicious and may reveal an entry point in the graph. Any suspicious activity involving this account should be reported in the graph and that's why we increase the weight of all path going out of this account at this timestep. For example if $a$ at timestep $t_0$ is the entry point and the hacker then infects $a'$ at timestep $t'$ from $a$ we should first see an abnormal activity in $a$. This activity is reported in $S_1$ as an account with too much activity and $S_2$ as a territory widely explored and creates a weighted edges in $E_2$. Then when $a'$ is compromised, we should see an alert coming from $S_1$ but not always from $S_2$ especially because territories may be shared and only few services may be available from $a'$ and not from $a$. This will create a connection in $E_2$ coming from $(a,t^{(3)})$ to $(a',t')$. Then the longest path will take into account that $a$ has possibly be compromised and $a'$ linked to $a$ in $V$ has also possibly be compromised. This reinforces the idea that a hacker would start from $a$ to then move to $a'$. All those weights are small clues of abnormal activity of the network. The temporal integration of those clues makes it possible to have better predictions of suspicious activities like lateral movements and to integrate them over the whole graph.

To compute the longest path we then add a node $(START,0)$ connected to all $(a\in V_a,t_0)$ with $t_0$ the first time marker of $time$ and weight 0 and a final node $(END,\infty)$ connected to all $(a\in V_a,t_{-1})$ with $t_{-1}$ the last time maker of $time$ and weight 0. 

We finally compute the longest path between $(START,0)$ and $(END,\infty)$ and compare its length to a treshold value $\beta$ (to be determined depending on the network). If the treshold is reached there is a security breach and we can get the possible path of the attacker with every account compromised as well as timesteps when they were compromised and we can have an idea about compromised services and data by analysing $S_1$ to see territories attacked. It also makes it possible to find the entry point to reinforce security in order to not be attacked similarly.

See annexe 1 for the global algorithm.

It's interesting to see that this method makes it possible to detect multiple independant lateral movements attacks in the network by return all paths with a length superior to $\beta$ and it could be interesting to investigate further in this direction.

The only part to train is the node anomaly algorithm which can easily be trained on data from a normal usage of the network or with a long recording time to get an 'average' effect on data.

\section{How to change passwords very often}
The best method to get rid of lateral movements is to find an efficient way to change passwords combined with an efficient algorithm to spot fast lateral movements. How to change password very often without being too unconvenient for users ? If you change passwords every hour and that everyone is remotely using a service gets disconected and then need to find the new password in a mail on an other account it may become very tricky to work efficiently. Moreover sending passwords to other mail adresses is a security breach because hackers may get access to this mail account and the whole process would be pointless.

That's why users need to have access to those passwords without sending them. An idea would be to print it on a screen in the office but the concept is to secure remote access so it would also be pointless for people working from home.

The best idea is probably for people to know their passwords as they change. They won't learn a password but a sequence of passwords (an unperiodic sequence to avoid failures). However learning a sequence of passwords such as 
\begin{equation}
\begin{split}
Agdb14Asfgjk47qs\mbox{ 18/05-09:00}\\
gHjslf54as8f5123\mbox{ 18/05-10:00}\\
Sgfbvj7412as575\$\mbox{ 18/05-11:00}\\
,hgs78\$asnqgFH\mbox{ 18/05-12:00}\\
jgavsgHSN78S214\mbox{ 18/05-13:00}\\
...
\end{split}
\end{equation}
is not realistic. That's why we will use a trick : instead of using a simple password it's possible to create a sequence of passwords from it using an other environmental information the authentification server has access to (such as date and time). The real password would be encoded using the standard password and date and time.
$$ real\_password = f(standard\_password,environmental\_data)$$
This way as soon as the user knows f and its $standard\_password$ he can compute his $real\_password$ to use during this hour. To be more convenient, f should be a function easily computable (idealy on the fly / without using a paper - which means with small memory usage and low computational power).
The easiest function is probably to concatenate both the $standard\_password$ and $environmental\_data$ but hackers may get access to few $real\_password$ through phishing and may understand $f$ and $environmental\_data$ used very quickly.
The challenge is to build a function $f$ easily computable "on the fly" and with a more secure encoding. Let's try this :\\
\begin{equation}
\begin{split}
\mbox{$standard\_password="Arthropoda"$}\\
AAAroda\mbox{ 18/05-09:00}\\
AAArrod\mbox{ 18/05-10:00}\\
AArrrod\mbox{ 18/05-11:00}\\
AAArtod\mbox{ 18/05-12:00}\\
AAArhod\mbox{ 18/05-13:00}\\
...
\end{split}
\end{equation}
You have probably understood that $f$ counts the number of each digit in the daytime format and uses a 10 characters $standard\_password$ to multipy the number of characters by the number of digits equal to its index. It's less obvious than concatenating and if you don't know that we are using and encoding with $"Arthropoda"$ as $standard\_password$ and daytime as $environmental\_data$ is pretty hard to understand the scheme only by getting very few samples of passwords.

This function is pretty easy to compute in your head because once you know your passwords and indexes associated to each character (with few minutes of training it's easy to know them) you don't needs more than 3 seconds to compute it.

Nonetheless it has statistical failures because daytime uses less '9' than '1' for example and with several samples it may be possible to understand that daytime is used and in the end find $f$ and $standard\_password$ right after it. However it would need many samples which means probably years of phishing to get through this protection. $f$ could then be changed each month or each year or even changed through a sequence of $f$ computable in your head without paper and thus be completely impossible to breach. Each changes of $f$ may take few mounth to spot assuming that phising works very fine (which is not the case due to massive warning campaigns about dangers of phising) and finding the scheme of the meta-$f$ function which gives all $f$ functions would take tens of thousand years to find.

It could be very interesting to investigate further and to find other $f$ easy to compute "on the fly" and more secure than those two presented previously.

\section{Conclusion}
The best way to prevent lateral movements is probably combining password resets and a statistical analysis on the network. It's impossible to prevent any damage (phising an account and directly accessing files before the reset would be impossible to spot statistically). However combining both makes it possible to drastically reduce the damages hackers may cause on networks and the part of them they can explore. 

To make it short stay safe \& stay home and change passwords.

\bibliographystyle{unsrt}
\bibliography{biblio}

\newpage
\section{Annexe}
\subsection{Algorithms}
\begin{itemize}
\item Graphs A,S and V are globals. 

\item Types are Event,Service,Account,Stream,Weighted Stream,Set,Fingerprint,WeightedFingerprint and Graph.

\item Fingerprints are represented as sets (an element is in the set if it is reprensented as 1). 

\item WeightedFingerprints are sets of couples (node,weight).

\end{itemize}

\textbf{Remark} : The whole algorithm is designed to be run online which means each time new few events appear every data structure should be updated and give feedbacks in real time to network administrators (here it is defined as if we only have a whole new stream to analyse but it shows how data is used).

%\newpage
\begin{algorithm}[H]
 \KwData{Input event Stream : $stream$ - on $V_a\cup V_s$ from t=0 to t=$\Delta$t$<password\_time$ about $a\in V_a$ accessing $s\in V_s$ at a specific timestep $\tau$}
 \KwResult{Boolean : whether an attack is actually happening}
 
 $S_1'$ = NodeAnomaly(ComputeF1stream($stream$))\;
 $S_1$ = AccountCorrespondance($S_1'$); \tcc{to get a stream on $V_a$ and not $F_1$ anymore (see correspondances in part 2)}
 $S_2$ = NodeAnomaly(ComputeF2stream($stream$))\;
 $Temp_V$ = ComputeTempV($S_1\cup S_2$)\;
 $longest\_path$ = LongestPath($Temp_V$,$START$,$END$); \tcc{You can use a Dijkstra or A* there}
 \Return $longest\_path.length>\beta$\;
 \caption{Main algorithm}
\end{algorithm}

\begin{algorithm}[H]
 \KwData{Stream str}
 \KwResult{Stream on $F_1$}
 str' = Stream()\;
 \For{Event e in Stream str}{
	Service s = e.fingerprint.find\_service(); \tcc{There is exactly one service and one account per event in the input stream}
 	Set implied\_territories = $\{e\in F_1 \| s \in e\}$\;
 	Event s' = Event(e.timestep,implied\_territories)\;
 	str'.add(s')
	}
 \Return str'\;
 \caption{ComputeF1Stream}
\end{algorithm}

\begin{algorithm}[H]
 \KwData{Stream str}
 \KwResult{Stream on $F_2$}
 \tcc{It's basically the input stream}
 \Return str\;
 \caption{ComputeF2Stream}
\end{algorithm}

\begin{algorithm}[H]
 \KwData{Stream str on $F_i$ $(i\in\{0;1\})$}
 \KwResult{Weighted stream on the same $F_i$}
 \tcc{see paper \cite{node}. Should return a stream}
 Weighted Stream ws = WeightedStream\;
 \For{t in str.length}{
 	Stream str' = substream(str,t); \tcc{extracts the substream with first t timesteps}
 	WeightedFingerprint wf = WeightedFingerprint()\;
	 \For{Object o in str.fingerprint.domain}{ \tcc{the domain of fingerprints is the whole set in which fingerprints evolve ($F_1$ or $F_2$ here)}
	 	Boolean b,Weight w = ComputeNodeAnomaly(str,o); \tcc{see paper \cite{node} for details about the algorithm. It should return whether an anomaly is detected on the stream str for node o in the fingerprint in addition to the associated weight as defined in part 2 (distance between the real value of $M_i^{(j)}$ and average + confidence interval length). If b is false then the algorithm can return anything for w.}
	 	\If{b}{
	 		fw.add((o,w))
	 	}
	 }
	 \If{not fw.is\_empty()}{
	 	Weighted Event we = WeightedEvent(t,fw)\;
	 	str'.add(we)
	 }
	}
 \Return ws\;
 \caption{NodeAnomaly}
\end{algorithm}

\begin{algorithm}[H]
 \KwData{Weighted Stream wstr of $F_1$}
 \KwResult{Weighted Stream on $V_a$}
 WeightedStream wstr' = WeightedStream()\;
 \For{Weighted Event we in wstr}{
 	FingerPrint fg = we.fingerprint; \tcc{without weights}
 	Set accounts\_liked = $\{a\in V_a \| \{s\in V_s \| (a,s)\in E_{as}\} = \mbox{fg}\}$\;
 	WeightedFingerprint wfg = transfer\_weights(fg,accounts\_linked); \tcc{change the set the fingerprint works on and transfers horizontally weights to corresponding nodes}
 	WeightedEvent we' = WeightedEvent(we.timestep,wfg)\;
 	wstr'.add(we')
 }
 \Return wstr'\;
 \caption{AccountCorrespondances}
\end{algorithm}

\begin{algorithm}[H]
 \KwData{Weighted Stream ws $(S)$}
 \KwResult{Graph $Temp_V$}
 \tcc{see part 2 : $V_{Temp_V}$ and $E_{Temp_V} = E_1 \cup E_2$}
 \caption{ComputeTempV}
\end{algorithm}
\end{document}
